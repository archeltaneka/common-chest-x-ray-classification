{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, pad):\n",
    "    img_pad = np.pad(img, ((pad, pad), (pad,pad)), 'constant', constant_values=0)\n",
    "    \n",
    "    return img_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution2D:\n",
    "    def __init__(self, filter_shape, num_filters, padding, stride):\n",
    "        self.filter_shape = filter_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.filters = np.random.randn(num_filters, filter_shape[0], filter_shape[0]) # random initialization\n",
    "        \n",
    "    def iterate(self, img, filter_shape):\n",
    "        height, width = img.shape\n",
    "        height = int((height + 2 * self.pad_size - self.filter_shape[0]) / self.stride) + 1\n",
    "        width = int((width + 2 * self.pad_size - self.filter_shape[0]) / self.stride) + 1\n",
    "        # check for odd heights and widths\n",
    "        if height % 2 != 0 and width % 2 != 0:\n",
    "            height += 1\n",
    "            width += 1\n",
    "#         print(height)\n",
    "#         print(width)\n",
    "#         print(filter_shape[0]-1)\n",
    "        \n",
    "        for i in range(height-(filter_shape[0]-1)):\n",
    "            for j in range(width-(filter_shape[0]-1)):\n",
    "#                 i_start = i * self.stride\n",
    "#                 i_end = i_start + filter_shape[0]\n",
    "#                 j_start = j * self.stride\n",
    "#                 j_end = j_start * filter_shape[0]\n",
    "#                 output = img[i_start:i_end, j_start:j_end]\n",
    "                output = img[i*self.stride:(i*self.stride+filter_shape[0]), j*self.stride:(j*self.stride+filter_shape[0])]\n",
    "#                 print(output, i, j)\n",
    "                yield output, i, j # 'yield' keyword will return any values and continue from the last value returned\n",
    "    \n",
    "    def conv2d(self, inputs):\n",
    "#         print(\"Before padding: \", inputs.shape)\n",
    "        self.last_input = inputs # cache the last input for backpropagation\n",
    "    \n",
    "        # padding\n",
    "        if(self.padding.lower() == 'same'): # same padding\n",
    "            height, width = inputs.shape\n",
    "            \n",
    "            pad_size = int(((height * self.stride) - height + self.filter_shape[0] - 1) / 2)\n",
    "            self.pad_size = pad_size\n",
    "\n",
    "            inputs = padding(inputs, pad_size) # apply padding according to the pad_size\n",
    "            height, width = inputs.shape # reinitialize height and width with padded image\n",
    "\n",
    "            new_height = int((height + 2 * pad_size - self.filter_shape[0]) / self.stride) + 1\n",
    "            new_width = int((width + 2 * pad_size - self.filter_shape[0]) / self.stride) + 1\n",
    "            # check for odd heights and widths\n",
    "            if new_height % 2 != 0 and new_width % 2 != 0:\n",
    "                new_height += 1\n",
    "                new_width += 1\n",
    "                \n",
    "            output = np.zeros((new_height, new_width, self.num_filters))\n",
    "            \n",
    "        elif(self.padding.lower() == 'valid'): # valid/no padding\n",
    "            height, width = inputs.shape\n",
    "            self.pad_size = 0\n",
    "            output = np.zeros((height-(self.filter_shape[0]-1), width-(self.filter_shape[0]-1), self.num_filters))\n",
    "            \n",
    "#         print(\"After padding: \", inputs.shape)\n",
    "        \n",
    "        for region, i, j in self.iterate(inputs, self.filter_shape):\n",
    "            output[i, j] = np.sum(region * self.filters, axis=(1,2))\n",
    "        \n",
    "#         print(\"After convolution: \", output.shape)\n",
    "        return output\n",
    "\n",
    "    def back_propagation(self, dL, learning_rate):\n",
    "        dL_filters = np.zeros(self.filters.shape)\n",
    "        \n",
    "        for img_region, i, j in self.iterate(self.last_input, self.filter_shape):\n",
    "            for k in range(self.num_filters):\n",
    "                dL_filters[k] += dL[i, j, k] * img_region\n",
    "        \n",
    "        # don't forget to update the filters\n",
    "        self.filters -= learning_rate * dL_filters\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "    \n",
    "    def iterate(self, img):\n",
    "        height, width, _ = img.shape\n",
    "        h = height//self.pool_size\n",
    "        w = width//self.pool_size\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                new_region = img[(i*self.pool_size):(i*self.pool_size+self.pool_size), \n",
    "                                 (j*self.pool_size):(j*self.pool_size+self.pool_size)]\n",
    "                yield new_region, i, j\n",
    "    \n",
    "    def pool(self, inputs):\n",
    "        self.last_input = inputs # cache the last input for backpropagation\n",
    "        \n",
    "        height, width, num_filters = inputs.shape\n",
    "        output = np.zeros((height//self.pool_size, width//self.pool_size, num_filters))\n",
    "        \n",
    "        for img_region, i, j in self.iterate(inputs):\n",
    "            output[i, j] = np.max(img_region, axis=(0,1))\n",
    "        \n",
    "#         print(\"After pooling: \", output.shape)\n",
    "        return output\n",
    "    \n",
    "    # backpropagation\n",
    "    def back_propagation(self, dL_output):\n",
    "        dL_input = np.zeros((self.last_input.shape))\n",
    "        \n",
    "        for img_region, i, j in self.iterate(self.last_input):\n",
    "            height, width, num_filters = img_region.shape\n",
    "            # find the max value for each region\n",
    "            maxi = np.max(img_region, axis=(0,1))\n",
    "            \n",
    "            for k in range(height):\n",
    "                for l in range(width):\n",
    "                    for m in range(num_filters):\n",
    "                        if img_region[k, l, m] == maxi[m]: # if the max values match, copy the gradient\n",
    "                            dL_input[i*2+k, j*2+l, m] = dL_output[i, j, m]\n",
    "        return dL_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    # initialize random weights and zero biases\n",
    "    def __init__(self, num_features, num_nodes, activation):\n",
    "        self.weights = np.random.randn(num_features, num_nodes) / num_features\n",
    "        self.biases = np.zeros(num_nodes)\n",
    "        self.activation = activation\n",
    "#         print(self.weights.shape)\n",
    "#         print(self.biases.shape)\n",
    "    \n",
    "    # flattens out the previous layer\n",
    "    def flatten(self, inputs):\n",
    "        self.inputs = inputs.flatten()\n",
    "#         print(self.inputs.shape)\n",
    "    \n",
    "    # connects flattened layer with a fully connected layer (dense)\n",
    "    def dense(self, inputs):\n",
    "        self.last_input_shape = inputs.shape # cache the last input shape BEFORE FLATTENING\n",
    "        \n",
    "        inputs = inputs.flatten() # flatten\n",
    "        self.last_input = inputs # cache the last input shape AFTER FLATTENING\n",
    "        input_features, nodes = self.weights.shape\n",
    "        \n",
    "        z = np.dot(inputs, self.weights) + self.biases # z = W . X + b\n",
    "        self.z = z # cache z for backpropagation\n",
    "        \n",
    "        if(self.activation.lower() == 'softmax'):    \n",
    "            a = np.exp(z) # a = g(z)\n",
    "            return a / np.sum(a, axis=0) # e^a / sum(a)\n",
    "        \n",
    "        elif(self.activation.lower() == 'relu'):\n",
    "            return max(0, z)\n",
    "    \n",
    "    # forward propagate phase\n",
    "    def forward_propagation(self, img, label, output, reg_lambda):\n",
    "        # -log(x) --> softmax loss function\n",
    "        loss = (-np.log(output[label])) + (1/2 * reg_lambda * np.sum(self.weights ** 2)) # + regularization term\n",
    "        acc = 1 if np.argmax(output) == label else 0 # increase the accuracy if the predicted label = actual label\n",
    "\n",
    "        return output, loss, acc\n",
    "    \n",
    "    def back_propagation(self, dL, learning_rate, reg_lambda):\n",
    "        for i, grad in enumerate(dL):\n",
    "            if grad == 0: continue; # ignores 0 gradient\n",
    "            \n",
    "            exp_total = np.exp(self.z) # total of e^\n",
    "            exp_sum = np.sum(exp_total) # sum of e^\n",
    "            \n",
    "            # gradients of z against totals\n",
    "            dz = -exp_total[i] * exp_total / (exp_sum ** 2)\n",
    "            dz[i] = exp_total[i] * (exp_sum - exp_total[i]) / (exp_sum ** 2)\n",
    "            \n",
    "            # gradients of totals against weights, biases, inputs\n",
    "            dt_dw = self.last_input\n",
    "            dt_db = 1\n",
    "            dt_di = self.weights\n",
    "            \n",
    "            # gradients of loss against totals\n",
    "            dL_dt = grad * dz\n",
    "            \n",
    "            # gradients of loss against weights, biases, and inputs\n",
    "            dL_dw = np.dot(dt_dw[np.newaxis].T, dL_dt[np.newaxis])\n",
    "            dL_db = dL_dt * dt_db\n",
    "            dL_di = np.dot(dt_di, dL_dt)\n",
    "            \n",
    "            # add the regularization term\n",
    "            dL_dw += reg_lambda * self.weights\n",
    "            \n",
    "            # update weights and biases\n",
    "            self.weights -= learning_rate * dL_dw\n",
    "            self.biases -= learning_rate * dL_db\n",
    "            \n",
    "            return dL_di.reshape(self.last_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create helper objects\n",
    "convolution = Convolution2D(filter_shape=(3,3), num_filters=8, padding='valid', stride=1)\n",
    "maxpool = MaxPool2D(pool_size=2)\n",
    "temp = convolution.conv2d(x_train[0]/255) # save img dimensions\n",
    "temp = maxpool.pool(temp)\n",
    "tmp_shape = temp.shape\n",
    "softmax = Softmax(tmp_shape[0]*tmp_shape[1]*tmp_shape[2], 10, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image):\n",
    "    # initialize the architecture\n",
    "    model = convolution.conv2d(image/255)\n",
    "    model = maxpool.pool(model)\n",
    "    model = softmax.dense(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(img, label, learning_rate):\n",
    "    \n",
    "    # initialize model\n",
    "    train_model = build_model(img)\n",
    "\n",
    "    # forward propagation step\n",
    "    output, loss, acc = softmax.forward_propagation(img, label, train_model, reg_lambda=1e-3)\n",
    "    \n",
    "    # initial gradient\n",
    "    grad = np.zeros(10) # 10 different classes\n",
    "    grad[label] = -1 / output[label]\n",
    "    \n",
    "    # back propagation\n",
    "    grad = softmax.back_propagation(grad, learning_rate, reg_lambda=1e-3)\n",
    "    grad = maxpool.back_propagation(grad)\n",
    "    grad = convolution.back_propagation(grad, learning_rate)\n",
    "    \n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, lr):\n",
    "    NUM_EPOCHS = epochs\n",
    "    learning_rate = lr\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):  \n",
    "        print(\"============= EPOCH\", epoch+1, \"=============\")\n",
    "        total_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        for i, (img, label) in enumerate(zip(x_train[:1000], y_train[:1000])): # let's train first 1000 data for simplicity \n",
    "            # build the complete model\n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print(\"Step\", i, \": Loss= \", total_loss/100, \"| Accuracy=\", accuracy, \"%\")\n",
    "\n",
    "                total_loss = 0\n",
    "                accuracy = 0\n",
    "            loss, acc = compile_model(img, label, learning_rate)\n",
    "            total_loss += loss\n",
    "            accuracy += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= EPOCH 1 =============\n",
      "Step 100 : Loss=  0.3090690285374802 | Accuracy= 92 %\n",
      "Step 200 : Loss=  0.32185951252052347 | Accuracy= 91 %\n",
      "Step 300 : Loss=  0.34836968166673904 | Accuracy= 90 %\n",
      "Step 400 : Loss=  0.2034372060644627 | Accuracy= 95 %\n",
      "Step 500 : Loss=  0.31994210861340444 | Accuracy= 89 %\n",
      "Step 600 : Loss=  0.33442229868164 | Accuracy= 93 %\n",
      "Step 700 : Loss=  0.39600325503921574 | Accuracy= 88 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-65e4527f02bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-d85696827cf3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, lr)\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-434b4ea976b1>\u001b[0m in \u001b[0;36mcompile_model\u001b[1;34m(img, label, learning_rate)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-bcffa112a2ea>\u001b[0m in \u001b[0;36mback_propagation\u001b[1;34m(self, dL, learning_rate)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg_region\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mdL_filters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimg_region\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m# don't forget to update the filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(3, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "def test(X_test, y_test):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for img, label in zip(X_test, y_test):\n",
    "        test_model = build_model(img)\n",
    "        _, l, acc = softmax.forward_propagation(img, label, test_model, reg_lambda=1e-3)\n",
    "        loss += l\n",
    "        accuracy += acc\n",
    "\n",
    "    print(\"Test Loss: \", loss/len(X_test))\n",
    "    print(\"Test Accuracy: \", accuracy/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.5488134145175944\n",
      "Test Accuracy:  0.826\n"
     ]
    }
   ],
   "source": [
    "test(x_test[:1000], y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_graph(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss vs Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_acc_graph(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Training Accuracy vs validation Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
