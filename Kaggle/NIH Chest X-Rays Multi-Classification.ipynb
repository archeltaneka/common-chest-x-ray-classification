{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dissertation Project Code: Common Chest X-ray Classification and Localization with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intended for my Dissertation Project at The University of Nottingham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset available at: https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing some of the libraries that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# keras tensorflow and other image processing libraries\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications import VGG16, VGG19, MobileNet, MobileNetV2, InceptionResNetV2, InceptionV3, ResNet50, DenseNet121, DenseNet169, DenseNet201\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "# scikit-learn libraries for utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# set random seed\n",
    "import random\n",
    "random.seed(111)\n",
    "\n",
    "print(os.listdir(\"../input\")) # list items inside the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if we are in the correct directory, we can list all of the items inside it. If all the items inside the directory are all printed out, we are in the correct directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring, Visualizing, and Pre-processing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General patients' information are stored inside the 'Data_Entry_2017.csv'. This is some kind of \"medical documents\" containing the patients' personal information (age and gender), image file name, and the disease labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../input/Data_Entry_2017.csv')\n",
    "\n",
    "total_data = len(data)\n",
    "print('Total number of data:', total_data) # total number of data\n",
    "\n",
    "data.head(5) # view first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that we have 112,120 total number of images in our directory with about 2500x2000 dimensions each image. It is a **VERY BIG DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the image processing and training part, it is always a good practice to analyse the .csv data. We might get some useful insights later while attempting to build the training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Analysing Patients' Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's group male and female patients according to their ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of age by its gender\n",
    "g = sns.catplot(data=data, col='Patient Gender', x='Patient Age', kind='count')\n",
    "g.set_xticklabels(np.arange(0,100));\n",
    "g.set_xticklabels(step=10);\n",
    "g.fig.suptitle('Age Distribution by Gender',fontsize=11);\n",
    "g.fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like both female and male patient in their 50s-60s are the biggest number of patients in the data according to the gender respectively. The number of male patients are also higher than the female patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Analysing the Diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the diseases into different groups according to their names. Keep in mind that a single chest x-ray can have different diseases which is separated by '|' sign (e.g. Mass|Hernia|Nodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69a30c7f88092bb2bfebb432d369a8b794f66568",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create an array of 14 diseases for one-hot encoding\n",
    "diseases = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', \n",
    "'Cardiomegaly', 'Nodule', 'Mass', 'Hernia'] # taken from paper\n",
    "\n",
    "for label in diseases:\n",
    "    data[label] = data['Finding Labels'].map(lambda result: 1 if label in result else 0)\n",
    "data.head(20) # check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we created another columns with the disease name as its header. These columns are useful when we build our training model. This method is also known as **one-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this block of code, we create a temporary dataframe which only contains 'Image Index', 'Finding Labels', 'Follow-up #', 'Patient ID', 'Patient Age', and 'Patient Gender' for analysing the diseases.\n",
    "We don't want to change anything from our original dataframe (data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new temporary dataframe for further analysis\n",
    "temp = data[['Image Index','Finding Labels','Follow-up #','Patient ID','Patient Age','Patient Gender']]\n",
    "for i in diseases:\n",
    "    temp[i] = data['Finding Labels'].map(lambda x: 1 if i in x else 0)\n",
    "temp['Nothing'] = data['Finding Labels'].map(lambda x: 1 if 'No Finding' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the 'temp' dataframe for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the diseases against the patients' gender\n",
    "gender_split = pd.melt(temp,\n",
    "             id_vars='Patient Gender',\n",
    "             value_vars=diseases,\n",
    "             var_name='Category',\n",
    "             value_name='Count')\n",
    "gender_split = gender_split.loc[gender_split.Count>0]\n",
    "g = sns.countplot(y='Category',hue='Patient Gender',data=gender_split, order = gender_split['Category'].value_counts().index)\n",
    "g.set_title('Individual Disease Count by Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize patients with 'No Finding' labels against the patients' gender\n",
    "gender_split_nothing = pd.melt(temp,\n",
    "             id_vars='Patient Gender',\n",
    "             value_vars = list(['Nothing']),\n",
    "             var_name = 'Category',\n",
    "             value_name = 'Count')\n",
    "gender_split_nothing = gender_split_nothing.loc[gender_split_nothing.Count>0]\n",
    "g = sns.countplot(y='Category',hue='Patient Gender',data=gender_split_nothing)\n",
    "g.set_title('No Finding Count Disease by Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can discover some findings\n",
    "* Patients with Infiltration is the highest and Hernia is the lowest.\n",
    "* The number of male patients in all diseases is higher than female patients except for Cardiomegaly and Hernia\n",
    "* The number of male patients is also higher than female patients for 'No Finding' x-rays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption: This imbalance data might affect our training model since it can get biased towards the x-ray infected with Infiltration disease**\n",
    "\n",
    "Remember that this is just an assumption we make by just looking at the graph above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the 'Finding Labels' for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of data\n",
    "count_per_unique_label = data['Finding Labels'].value_counts() # get frequency counts per label\n",
    "df_count_per_unique_label = count_per_unique_label.to_frame() # convert series to dataframe for plotting purposes\n",
    "\n",
    "print(df_count_per_unique_label) # view tabular results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have 836 different states of chest x-ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we can just look at the diseases in the top 20 and convert them into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = df_count_per_unique_label.index[:20], y=\"Finding Labels\", data=df_count_per_unique_label[:20]), plt.xticks(rotation = 90)\n",
    "plt.title('Label Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that 'No Finding' label outnumbers all diseases with a very big gap, but don't worry since this is a real-world data that we might also encounter in medical imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's leave the 'No Finding' label out and group patients with multiple diseases and count them in according to the disease. \n",
    "\n",
    "For example:\n",
    "Patient with Infiltration | Nodule | Mass is counted in to Infiltration, Nodule, and Mass individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f084fec6514a9fac1323f80ca0108bee912c4c4"
   },
   "outputs": [],
   "source": [
    "# create clean labels for the diseases which exclude the 'No Finding' label\n",
    "clean_labels = data[diseases].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(clean_labels) # view tabular results\n",
    "\n",
    "# plot the data\n",
    "clean_labels_df = clean_labels.to_frame()\n",
    "sns.barplot(x = clean_labels_df.index[::], y=0, data = clean_labels_df[::]), plt.xticks(rotation=90)\n",
    "plt.title('Diseases distribution without \"No Finding\" label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like infiltration is the most common diseases from both gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's breakdown the graph above into individual graphs according to the diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize individual disease against patients' age, associated with gender\n",
    "f, ax = plt.subplots(7, 2, sharex=True, figsize=(15, 20)) # 7x2 subplots with shared x value, 15x20 size\n",
    "i = j = 0 # variables to iterate between subplots\n",
    "x=np.arange(0,100,10)\n",
    "for disease in diseases:\n",
    "    g = sns.countplot(x='Patient Age', hue='Patient Gender', data=data[data['Finding Labels'] == disease], ax=ax[i,j])\n",
    "    ax[i, j].set_title(disease)   \n",
    "    g.set_xlim(0,90)\n",
    "    g.set_xticks(x)\n",
    "    g.set_xticklabels(x)\n",
    "    j=(j+1)%2\n",
    "    if j==0:\n",
    "        i=(i+1)%7\n",
    "f.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see something unusual here?\n",
    "> All graphs are quite evenly distributed, showed by a bell curve in each graph. The peak (highest curve) in the middle of the graph represents the variability of data dispersion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is not the case for patients with Hernia. Let's do a quick research about this disease (https://www.niddk.nih.gov/health-information/digestive-diseases/inguinal-hernia#who)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what I got:\n",
    "* **Adults from 75-80** are the most likely to have hernia\n",
    "* **Children** can also get hernia between **age 0-5**\n",
    "* Hernia are also commonly found in **premature infants**\n",
    "\n",
    "However, if we look at Hernia patients graph, patients with this disease are commonly found in between 10s to 30s group age. This is an interesting finding because our findings contradict with the information we got from the NIH website above.\n",
    "For now, let's move on to the next analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare patients who have multiple diseases in their x-rays with patients who only have one disease. We can also count how many unique labels that occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91d483c23e8e6f9c97ce56c4c43222bd0d17ffef"
   },
   "outputs": [],
   "source": [
    "# count unique labels in the dataset\n",
    "num_unique_labels = data['Finding Labels'].nunique()\n",
    "print('Number of unique labels:',num_unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare between single and multiple diseases\n",
    "multi_and_single_disease_split = temp.groupby('Finding Labels').count().sort_values('Patient ID', ascending=False)\n",
    "multi = multi_and_single_disease_split[['|' in i for i in multi_and_single_disease_split.index]].copy()\n",
    "single = multi_and_single_disease_split[['|' not in i for i in multi_and_single_disease_split.index]]\n",
    "single = single[['No Finding' not in i for i in single.index]]\n",
    "\n",
    "single['Finding Labels'] = single.index.values\n",
    "multi['Finding Labels'] = multi.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize between single vs multiple diseases\n",
    "f, ax = plt.subplots(sharex=True,figsize=(8, 5))\n",
    "sns.countplot(y='Category', data=gender_split, ax=ax, order=gender_split['Category'].value_counts().index,\n",
    "              color='b', label=\"Multiple Diseases\")\n",
    "sns.barplot(x='Patient ID', y='Finding Labels', data=single, ax=ax, color='r', label='Single Disease')\n",
    "ax.legend(ncol=2, loc=\"center right\", frameon=True, fontsize=10) \n",
    "ax.set(ylabel=\"Type of disease\", xlabel=\"Number of Patients\")\n",
    "ax.set_title(\"Comparison between Single vs Multiple Diseases\",fontsize=12) \n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of patients with multiple diseases are higher than patients who only have one disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Analysing the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading images are rather inconvenience with this dataset. Here's the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In it is very common that dataset in a directory is managed in this fashion\n",
    "\n",
    "1. Main Directory<br>\n",
    "    1.1. CLASS_1\n",
    "        1.1.1. Train\n",
    "        1.1.2. Validation\n",
    "        1.1.3. Test\n",
    "    1.2. CLASS_2\n",
    "        1.2.1. Train\n",
    "        1.2.2. Validation\n",
    "        1.2.3. Test\n",
    "    1.3. CLASS_3\n",
    "        1.3.1. Train\n",
    "        1.3.2. Validation\n",
    "        1.3.3. Test\n",
    "<br>\n",
    "By managing the directory like this, image processing and data augmentation becomes easier since the data has been \"tidied up\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why we create a glob object, then create a new column to store the full path to each image in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59d78b4cb047df620df9c736b0f670c6e42b2940"
   },
   "outputs": [],
   "source": [
    "# create glob object\n",
    "my_glob = glob('../input/images*/images/*.png')\n",
    "print('Number of Observations: ', len(my_glob)) # should be 112120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "118b0dec8fec5fff77526675c571a0e918e6a2d2"
   },
   "outputs": [],
   "source": [
    "# store the image paths onto data\n",
    "full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
    "data['full_path'] = data['Image Index'].map(full_img_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the image using our new column \"full_path\" to check whether it is the correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups the image paths by according to the disease\n",
    "image_split = data.groupby(['Finding Labels', 'full_path']).count().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emphysema\n",
    "disease_path = image_split[['Emphysema' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atelectasis\n",
    "disease_path = image_split[['Atelectasis' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation\n",
    "disease_path = image_split[['Consolidation' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infiltration\n",
    "disease_path = image_split[['Infiltration' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pneumothorax\n",
    "disease_path = image_split[['Pneumothorax' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edema\n",
    "disease_path = image_split[['Edema' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibrosis\n",
    "disease_path = image_split[['Fibrosis' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effusion\n",
    "disease_path = image_split[['Effusion' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pneumonia\n",
    "disease_path = image_split[['Pneumonia' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pleural Thickening\n",
    "disease_path = image_split[['Pleural_Thickening' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardiomegaly\n",
    "disease_path = image_split[['Cardiomegaly' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodule\n",
    "disease_path = image_split[['Nodule' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass\n",
    "disease_path = image_split[['Mass' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hernia\n",
    "disease_path = image_split[['Hernia' in i for i in image_split]]\n",
    "disease_img = []\n",
    "for i in range(len(disease_path)):\n",
    "    disease_img.append(disease_path[i][1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for (x, a) in zip(disease_img, ax):\n",
    "    t = plt.imread(x)\n",
    "    a.imshow(t, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing to do. Remember the one-hot encoding we created in the beginning of this notebook? Now we have to combine those 0s and 1s into one single array in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fe62519bea916e07783f6fb51b51244eb35fd7a"
   },
   "outputs": [],
   "source": [
    "# creates 'target_vector' column to combine the one-hot encoding\n",
    "data['target_vector'] = data.apply(lambda target: [target[diseases].values], 1).map(lambda target: target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd98d0661e968569a25234aa8de4ccc93f6080bf"
   },
   "outputs": [],
   "source": [
    "data.head() # check the 'target_vector' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we are ready to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are going to use is split into train/validation/test with split of 80/10/10 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ecd0a5bedde801a2fff9babb43b27e5ab42ac20"
   },
   "outputs": [],
   "source": [
    "# split the data into training, validation, and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 80/10/10 split\n",
    "train_set, val_set = train_test_split(data, test_size=0.1, random_state=1993)\n",
    "train_set, test_set = train_test_split(train_set, test_size=0.1, random_state=1993)\n",
    "\n",
    "print('Training: ', len(train_set))\n",
    "print('Validation: ', len(val_set))\n",
    "print('Testing: ', len(test_set))\n",
    "print('Total data: ', len(data))\n",
    "print(len(train_set)+len(test_set)+len(val_set) == len(data)) # double check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has a convenient method to do data augmentation which is ImageDataGenerator. Data augmentation is one of the alternatives to make training data more variant by applying some image processing such as: zoom, rotation, shift, shear, flip, etc.<br><br>\n",
    "\n",
    "Notice that ** we only normalize and do not apply any data augmentation in the test set**. This is due to the nature of medical imaging. When we are in a hospital, having our chest scanned, we do not receive a zoomed, rotated, shifted, or flipped image of our chest x-ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6df03acb095f2fa31bcb3cb10a4b655bf0cae18b"
   },
   "outputs": [],
   "source": [
    "# creates image data generator for both training and testing images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255) # we don't want to apply zoom, rotation, shear, etc. in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flow_from_dataframe function below will help us to acquire image in the directory by referring to our dataframe that has been created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06a9e1992fd8414e7b69832ec354efd895158c68"
   },
   "outputs": [],
   "source": [
    "# Credits to Kevin Mader who created this function\n",
    "# https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "\n",
    "# flow_from_dataframe is a function that takes a full path of an image from the dataframe we created earlier,\n",
    "# instead from the directory\n",
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we already have full_path column, we can set this to None or ''\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the data augmentation to training, validation, and testing data.<br>\n",
    "* Here we set color_mode to RGB because we are going to use pre-trained models. These pre-trained models only accept input with 3 color channels. \n",
    "* We can try different input size by changing image_size, most pre-trained models accept input image with 224x224 pixels\n",
    "* We set 1024 batch on test set to make predictions faster by taking a big batch of data while training and validation can be set to 32, 64, 128 or higher. When memory error occurs, lower the batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a259046bb30625e394e01a913965466c09f315d4"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224) # image re-sizing\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 1024\n",
    "\n",
    "# train dataset\n",
    "train_gen = flow_from_dataframe(train_data_gen, train_set, path_col = 'full_path', y_col = 'target_vector',\n",
    "                                target_size = IMG_SIZE, color_mode = 'rgb', batch_size = TRAIN_BATCH_SIZE)\n",
    "# validation dataset\n",
    "valid_X, valid_Y = next(flow_from_dataframe(train_data_gen, val_set, path_col = 'full_path',\n",
    "                                            y_col = 'target_vector', target_size = IMG_SIZE, \n",
    "                                            color_mode = 'rgb', batch_size = VAL_BATCH_SIZE))\n",
    "# test dataset\n",
    "test_X, test_Y = next(flow_from_dataframe(test_data_gen, test_set, path_col = 'full_path', y_col = 'target_vector', \n",
    "                                          target_size = IMG_SIZE, color_mode = 'rgb', batch_size = TEST_BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the images in the training data and test data which have been augmented by the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the images from the train/validation data generator\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap='bone')\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(diseases, c_y) \n",
    "                             if n_score>0.5])) # n_score will find the '1' inside 14 indexes\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the images from the test data generator\n",
    "t_x, t_y = test_X, test_Y\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(diseases, c_y) \n",
    "                             if n_score>0.5])) # n_score will find the '1' inside 14 indexes\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is for experiments. We can build our own model or use the pre-trained models with various hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc33470406693823f124417cbc297fa61fdb3aa9"
   },
   "outputs": [],
   "source": [
    "# # Create the model\n",
    "# my_model = Sequential()\n",
    "\n",
    "# my_model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = test_X.shape[1:]))\n",
    "# # my_model.add(MaxPooling2D(pool_size = 2))\n",
    "# my_model.add(Dropout(0.2))\n",
    "\n",
    "# my_model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "# # my_model.add(MaxPooling2D(pool_size = 2))\n",
    "# my_model.add(Dropout(0.2))\n",
    "          \n",
    "# my_model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "# # my_model.add(MaxPooling2D(pool_size = 2))\n",
    "# my_model.add(Dropout(0.2))\n",
    "\n",
    "# my_model.add(Conv2D(filters = 256, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "# # my_model.add(MaxPooling2D(pool_size = 2))\n",
    "# my_model.add(Dropout(0.2))\n",
    "\n",
    "# my_model.add(GlobalAveragePooling2D())\n",
    "# my_model.add(Dropout(0.2))\n",
    "\n",
    "# my_model.add(Flatten())\n",
    "# my_model.add(Dense(256, activation = 'relu'))\n",
    "# my_model.add(Dropout(0.2))\n",
    "# my_model.add(Dense(len(diseases), activation = 'softmax'))\n",
    "\n",
    "# my_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', 'mae'])\n",
    "# my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model with transfer learning\n",
    "Base : VGG16, VGG19, MobileNet, MobileNetV2, InceptionResNetV2, InceptionV3, ResNet50, DenseNet121, DenseNet169, DenseNet201\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts all images to 3 color channels, because pre-trained models only use RGB color channel\n",
    "\n",
    "base_choice = 'VGG16'\n",
    "# VGG16\n",
    "if base_choice.upper() == 'VGG16':\n",
    "    base_model = VGG16(include_top=False, input_shape=(224,224,3), weights='imagenet')\n",
    "# VGG19\n",
    "elif base_choice.upper() == 'VGG19':   \n",
    "    base_model = VGG19(include_top=False, input_shape=(224,224,3))\n",
    "# MobileNet\n",
    "elif base_choice.upper() == 'MOBILE':\n",
    "    base_model = MobileNet(include_top=False, input_shape=(224,224,3))\n",
    "# MobileNetV2\n",
    "elif base_choice.upper() == 'MOBILEV2':\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=(224,224,3))\n",
    "# InceptionResNetV2\n",
    "elif base_choice.upper() == 'INCEPTIONV2':\n",
    "    base_model = InceptionResNetV2(include_top=False, input_shape=(224,224,3))\n",
    "# InceptionV3\n",
    "elif base_choice.upper() == 'INCEPTIONV3':\n",
    "    base_model = InceptionV3(include_top=False, input_shape=(224,224,3))\n",
    "# ResNet50\n",
    "elif base_choice.upper() == 'RESNET50':\n",
    "    base_model = ResNet50(include_top=False, input_shape=(224,224,3))\n",
    "# DenseNet 121\n",
    "elif base_choice.upper() == 'DENSE121':\n",
    "    base_model = DenseNet121(include_top=False, input_shape=(224,224,3))\n",
    "# DenseNet 169\n",
    "elif base_choice.upper() == 'DENSE169':\n",
    "    base_model = DenseNet169(include_top=False, input_shape=(224,224,3))\n",
    "# DenseNet 201\n",
    "elif base_choice.upper() == 'DENSE201':\n",
    "    base_model = DenseNet201(include_top=False, input_shape=(224,224,3))\n",
    "    \n",
    "print(\"Base pre-trained model:\", base_choice)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using the pre-trained models, we need to freeze these layers since we do not want to pass any gradients back (backpropagation) later while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "# adds our own dense layers\n",
    "output = base_model.output\n",
    "output = Flatten()(output)\n",
    "output = Dense(256, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01))(output)\n",
    "last_output = Dense(14, activation='softmax')(output)\n",
    "# construct final model\n",
    "final_model = Model(base_model.input, last_output)\n",
    "# compile the model\n",
    "# opt = optimizers.Adamax(lr=0.02)\n",
    "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a weight during or after the training is important for reusability. This checkpoint will trigered if it finds better val_loss and save the model in our directory with the specified name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "814c8f40748209198add1ec9d324452c302affdc"
   },
   "outputs": [],
   "source": [
    "# set up a callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='weights.'+base_choice+ '.{epoch:d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only = True)\n",
    "callbacks_list = [checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training phase will take some time. Run it on GPU if you have one or use Kaggle for 30 hour weekly free GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec5333de52ae710c30c3c933ea17203f27a4fcbb"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "fitted_model = final_model.fit_generator(generator=train_gen, steps_per_epoch=len(train_gen)//TRAIN_BATCH_SIZE, epochs=5, validation_data=(valid_X, valid_Y), validation_steps=len(valid_X)//VAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this code below if we want to save the weight after the training is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# final_model.save('weights.'+base_choice+ '.{epoch:d}-{val_loss:.2f}.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC (Receiver Operating Characteristics) curve is one of the methods to measure the performance of a classification problem.\n",
    ">It tells how good our model to separate between classes (predicting 0s as 0s and 1s as 1s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has a good performance in separating classes if AUC (area under curve) is close to 1, otherwise close to 0 if model performs badly in separating classes\n",
    "![AUC-ROC Curve](https://miro.medium.com/max/451/1*pk05QGzoWhCgRiiFbz-oKQ.png)\n",
    "Image taken from https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions based on the trained model\n",
    "deep_model_predictions = final_model.predict(test_X, batch_size=len(test_X)//TEST_BATCH_SIZE, verbose=1)\n",
    "# plot ROC curve based on the predictions\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (i, label) in enumerate(diseases):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,i].astype(int), deep_model_predictions[:,i])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n",
    "\n",
    "# set labels for plot\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig(base_choice+'_roc.png') # save the roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or evaluate the model with the accuracy and loss metrics against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with the test set\n",
    "final_model.evaluate(test_X, test_Y, batch_size=len(test_X)//TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy into curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f0b50ce87ac0c3018e7069ec19ba8327a1a20c7"
   },
   "outputs": [],
   "source": [
    "print(fitted_model.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitted_model.history['loss'])\n",
    "plt.plot(fitted_model.history['val_loss'])\n",
    "plt.title('Model Loss vs Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitted_model.history['binary_accuracy'])\n",
    "plt.plot(fitted_model.history['val_binary_accuracy'])\n",
    "plt.title('Training Accuracy vs validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment, change the batch_size if necessary, and run the code below if you are running out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "# test_X, test_Y = next(flow_from_dataframe(test_data_gen, test_set, path_col = 'full_path', y_col = 'target_vector', \n",
    "#                                           target_size = image_size, color_mode = 'rgb', batch_size = 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction for a single image with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = final_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the localisation, we are going to use the CAM (Class Activation Map) algorithm. Later in different notebook, I will use another algorithm which is the \"upgraded\" version of CAM, which is the Grad CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined our model architecture and now it can predict the images, but what does it actually see inside the learning process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the final layer of the model\n",
    "saved_weights = final_model.layers[-1].get_weights()[0]\n",
    "saved_weights.shape\n",
    "# create a new model with the last convolutional layer as the output and the final predicted layer\n",
    "cam_model = Model(inputs=final_model.input, outputs=(final_model.layers[-14].output, final_model.layers[-1].output))\n",
    "\n",
    "features, res = cam_model.predict(test_X, batch_size=32) # make a new prediction with that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain CAM, these are the general steps:\n",
    "1. The Softmax layer (the last layer of our model) contains the probabilities for all classes\n",
    "2. The final convolutional layer from our model contains the weights to predict more complex pattern from the images. This is why we want the **final convolutional layer** to see what did they \"see\"\n",
    "3. Next, calculate the **dot product between the weights from the final layer and the feature map to produce the CAM (Class Activation Map)** and plot them into the subplots to convert those floating numbers into a more comprehensive format, which is color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\n",
    "# create subplots to plot different images\n",
    "fig, m_axs = plt.subplots(4, 2, figsize = (16, 16))\n",
    "for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n",
    "    indv_features = features[idx,:,:,:]\n",
    "    pred = np.argmax(res[idx]) # use np.argmax to find the highest probability\n",
    "\n",
    "    cam_features = indv_features # feature maps\n",
    "    cam_weights = saved_weights[:, pred] # the weights from the last layer\n",
    "    cam_output = np.dot(cam_features, cam_weights) # calculate the dot product\n",
    "    \n",
    "    c_ax.imshow(cam_output, cmap='jet')\n",
    "#     c_ax.imshow(test_X[idx,:,:,0], cmap = 'bone')\n",
    "    stat_str = [n_class for n_class, n_score in zip(diseases, test_Y[idx]) if n_score>0.5]\n",
    "    pred_str = ['%s:%2.0f%%' % (n_class, p_score*100) for n_class, n_score, p_score in zip(diseases, test_Y[idx], pred_Y[idx]) \n",
    "                if (n_score>0.5) or (p_score>0.5)]\n",
    "    c_ax.set_title('Label(s): '+', '.join(stat_str)+'\\n Prediction(s): '+', '.join(pred_str))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is rather confusing and does not tell us any information about the existence of the disease(s). Generally, the RGB colored pixels in the results are only the indicators which pattern the model found. \"Warmer\" pixel colors mean stronger correlation to the pattern, while \"cooler\" pixel colors mean otherwise (weaker correlation).<br><br>\n",
    "I will introduce another algorithm called Grad-CAM which is the upgraded version of this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
